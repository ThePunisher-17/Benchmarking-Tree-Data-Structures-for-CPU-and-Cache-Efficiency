# 🧾 Benchmarking Tree Data Structures for CPU and Cache Efficiency

## What We Did — Summary

This project performs a microarchitectural performance comparison of five tree data structures: Binary Search Tree (BST), AVL Tree, Red-Black Tree (RB), Treap, and van Emde Boas (vEB) layout.

We implemented all five trees in C++ and benchmarked them on uniformly random datasets (1K–1M elements) using low-level profiling tools (`perf`, `Cachegrind`). Each structure was evaluated on key CPU-level metrics—such as IPC, cache misses, branch mispredictions, pipeline stalls, and instruction retiring.

We visualized trends across dataset sizes and introduced a composite efficiency score to rank the trees holistically. The goal was to identify data structures best suited for modern, cache-sensitive, and CPU-bound applications.

---

# 📁 Repository Structure and File Descriptions

## Top-Level Files

- **`main.cpp`**
  Entry point for benchmarking. Defines all tree structures, generates random keys, and invokes insert/search/update/delete/predecessor/successor operations for each tree. Logs results to CSV and triggers profiling tools. Requires compilation with `-g` and `-O2` for best profiling visibility.

- **`benchmark`**
  Binary executable compiled from `main.cpp`. Used in shell script to run experiments.

- **`run_all_benchmarks.sh`**
  Shell script to automate multiple benchmark runs for each tree and dataset size. Runs `perf` and `valgrind --tool=cachegrind`, and stores outputs under `benchmark_results/`.

- **`callgrind.out.13141`**
  Cachegrind output file for a specific configuration. Can be analyzed using `cg_annotate`.

## 📁 `benchmark_results/`

Contains all profiling results.

### `csv/`

Contains CSV summary logs generated by each tree structure:

- `AVL_results.csv`
- `BST_results.csv`
- `RB_results.csv`
- `Treap_results.csv`
- `vEB_results.csv`

Each file has metrics like IPC, branch misses, frontend/backend stalls, etc., averaged across 3 runs.

### `cachegrind/`

Contains Cachegrind reports for each tree × dataset size. Naming format: `TREE_SIZE_cg_report.txt` (e.g., `RB_10000_cg_report.txt`).

Use `cg_annotate` to parse these files and extract L1, D1, and LLC cache stats.

### `perf/`

Contains `perf stat` output for each configuration. Files are named as `TREE_SIZE_perf.txt`. Includes cycles, instructions, branch misses, frontend/backend bound percentages, and retiring stats.

## 📁 `Plots/`

All generated plots used in the paper:

- `ipc_vs_size.png`
- `branch_miss_rate_vs_size.png`
- `frontend_bound_vs_size.png`
- `backend_bound_vs_size.png`
- `retiring_vs_size.png`
- `efficiency_score_vs_size.png`
- `composite_score_vs_size.PNG`
- `radar_chart_metrics.png`

These visualize performance trends across dataset sizes and highlight comparative efficiency.

---

# ⚙️ How to Reproduce the Experiments

### Requirements:

- GCC or Clang (with `-g` support)
- Valgrind (>= 3.18)
- Linux `perf`
- Bash shell for `.sh` script

### Steps:

1. Compile using:

   ```bash
   g++ -g -O2 main.cpp -o benchmark
   ```

2. Run all benchmarks:

   ```bash
   ./run_all_benchmarks.sh
   ```

This generates all perf and Cachegrind outputs in the `benchmark_results/` folder.

---

# 🔍 How to Interpret Outputs

### IPC (Instructions Per Cycle)

- Found in `perf.txt` files. Higher IPC = better throughput.

### Branch Miss Rate

- Ratio of `branch-misses / branches` from `perf` logs. Lower is better.

### Frontend/Backend Bound

- Extracted using `perf stat -d`. Reflect stalls in instruction fetch and memory access.

### Instruction Retiring

- `perf`'s top-down TMA model reports retiring %. Higher = more effective execution.

### Composite Efficiency Score

- A weighted score combining all metrics. Plotted in `efficiency_score_vs_size.png` and radar chart.

---

# 📜 Citation

If you use this code or analysis, please cite the corresponding paper:

> Pratik Deshmukh. "Benchmarking Tree Data Structures for CPU and Cache Efficiency." 2025. GitHub Repository: https://github.com/ThePunisher-17/Benchmarking-Tree-Data-Structures-for-CPU-and-Cache-Efficiency

---

# 🙏 Acknowledgements

Thanks to contributors and tools like Valgrind, perf, and Matplotlib for enabling this low-level performance study.
